<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Frame Extraction Example</title>
    <style>
        canvas {
            border: 1px solid black;
        }
    </style>
</head>
<body>
    <h1>Video Frame Extraction</h1>

    <!-- Embedded video player for playback -->
    <video width="640" height="360" controls>
        <source src="assets/video/sample640X360.webm" type='video/webm; codecs="vp9"'>
        Your browser does not support the video tag.
    </video>

    <!-- Canvas for displaying the extracted frame -->
    <canvas id="videoCanvas"></canvas>

    <script type="text/javascript" src="node_modules/@libav.js/variant-webm-vp9/dist/libav-5.4.6.1.1-webm-vp9.js"></script>
    <script type="text/javascript">
        document.addEventListener('DOMContentLoaded', async function() {
            try {
                const libav = await LibAV.LibAV();
                const videoData = await fetch("assets/video/sample640X360.webm").then(response => response.arrayBuffer());
                await libav.writeFile("sample640X360.webm", new Uint8Array(videoData));

                const [fmt_ctx, [stream]] = await libav.ff_init_demuxer_file("sample640X360.webm");
                const [, codecContext, packet, frame] = await libav.ff_init_decoder(stream.codec_id, stream.codecpar);
                const [, packets] = await libav.ff_read_frame_multi(fmt_ctx, packet);

                const frames = await libav.ff_decode_multi(codecContext, packet, frame, packets[stream.index], true);
                console.log(`Extracted ${frames.length} frames from the video!`);

                const canvas = document.getElementById('videoCanvas');
                const ctx = canvas.getContext('2d');
                canvas.width = 640;
                canvas.height = 360;

                if (frames.length > 0 && frames[0].data) {
                    const firstFrame = frames[200];
                    const yData = firstFrame.data.subarray(0, 640 * 360);
                    const uData = firstFrame.data.subarray(640 * 360, 640 * 360 + (640 * 360) / 4);
                    const vData = firstFrame.data.subarray(640 * 360 + (640 * 360) / 4, 640 * 360 + (640 * 360) / 2);

                    const rgbaData = convertYUV420ToRGB(yData, uData, vData, 640, 360);
                    const imgData = new ImageData(rgbaData, 640, 360);
                    ctx.putImageData(imgData, 0, 0);
                } else {
                    console.error("No frames available to display or data is not accessible");
                }
            } catch (error) {
                console.error("Failed to load or process the video:", error);
            }
        });

        function convertYUV420ToRGB(yData, uData, vData, width, height) {
            const rgbaData = new Uint8ClampedArray(width * height * 4);

            for (let y = 0; y < height; y++) {
                for (let x = 0; x < width; x++) {
                    const yIndex = y * width + x;
                    const uIndex = (Math.floor(y / 2) * Math.floor(width / 2)) + Math.floor(x / 2);
                    const vIndex = uIndex;

                    const Y = yData[yIndex];
                    const U = uData[uIndex] - 128;
                    const V = vData[vIndex] - 128;

                    const R = Y + 1.402 * V;
                    const G = Y - 0.344136 * U - 0.714136 * V;
                    const B = Y + 1.772 * U;

                    const rgbIndex = yIndex * 4;
                    rgbaData[rgbIndex] = R;
                    rgbaData[rgbIndex + 1] = G;
                    rgbaData[rgbIndex + 2] = B;
                    rgbaData[rgbIndex + 3] = 255; // Alpha channel
                }
            }
            return rgbaData;
        }
    </script>
</body>
</html>
